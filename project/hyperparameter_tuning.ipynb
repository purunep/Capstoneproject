{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import dependencies\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-132094\n",
      "Azure region: southcentralus\n",
      "Subscription id: 61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\n",
      "Resource group: aml-quickstarts-132094\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"capstone_project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: update the key to match the dataset name\n",
    "found = False\n",
    "key = \"diabetes-classification\"\n",
    "description_text = \"Diabetes datasets for capstone project\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True        \n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "        # Create Hyperdrive Dataset and register it into Workspace\n",
    "        url = 'https://raw.githubusercontent.com/purunep/Capstone/main/project/data/diabetes.csv'\n",
    "        dataset = Dataset.Tabular.from_delimited_files(url)        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()\n",
    "\n",
    "##from train import clean_data\n",
    "#[x_data, y_data] = clean_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "cpu_cluster_name = \"puru-compute-new\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
    "                                                           max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"tutorial-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-dataset-runtime[pandas,fuse]~=1.19.0\",\n",
       "                        \"azureml-defaults~=1.19.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn==0.22.1\"\n",
       "            ],\n",
       "            \"name\": \"azureml_e9628e39691fa30b1f8588e7375b026c\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# to install required packages\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Register environment to re-use later\n",
    "env.register(workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "args = ['--C', 0.5, '--max_iter', 10]\n",
    "\n",
    "src = ScriptRunConfig(source_directory='.',\n",
    "                      script='train.py', \n",
    "                      arguments=args,\n",
    "                      compute_target=cpu_cluster,\n",
    "                      environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>capstone_project</td><td>capstone_project_1609112943_031f3fe8</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/experiments/capstone_project/runs/capstone_project_1609112943_031f3fe8?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-132094/workspaces/quick-starts-ws-132094\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: capstone_project,\n",
       "Id: capstone_project_1609112943_031f3fe8,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=src)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8527d2e65e6c406f9a23316547d24214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/capstone_project/runs/capstone_project_1609112943_031f3fe8?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-132094/workspaces/quick-starts-ws-132094\", \"run_id\": \"capstone_project_1609112943_031f3fe8\", \"run_properties\": {\"run_id\": \"capstone_project_1609112943_031f3fe8\", \"created_utc\": \"2020-12-27T23:49:05.660716Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c318df8a-85be-41ed-a2e4-cecb29eb5aa8\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-12-27T23:59:50.495508Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=%2FKDAst2lGZQI%2BLaqjxgK%2Br6dPMnVnQJNHj3jR4n5zEc%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/55_azureml-execution-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt?sv=2019-02-02&sr=b&sig=MoOyc%2FCc%2BskEniFYoke50teodEPmn6B4Rex20TJe%2Ffo%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/65_job_prep-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt?sv=2019-02-02&sr=b&sig=EZf3CtyPKJie9O2dcyRdwcOH7bOAA0TYXXUxoetmRpo%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=c7OQZYa%2FA5OAmPnXTSNuR2h3QKXgGbYgrnz%2FO%2FVfkwQ%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/75_job_post-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/75_job_post-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt?sv=2019-02-02&sr=b&sig=JnxjjsLOr1brWCe8Ime%2FyjWDNbFf5wQFkuIeRK8zfB8%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=iU96NsDuvrzMLjic7lPzZiUimfR4eiKMEsMiDNU2LvA%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=kvZt8iYlkvfiKHDVVVOrvfuYpTwaVzE1ktEfWHcE4Yk%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/103_azureml.log\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/103_azureml.log?sv=2019-02-02&sr=b&sig=NZZZinwK0h9U2h7DQWaNdeksSddg8SMgBFiUDIcWDEs%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=rnKaoEAOS9LJns7LuS4b9jE2jI%2FblcjpEfvOgZUM79E%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=BdEQvyoxMHmFG4Zj7ehrQmaf45ny3SBOQkEMKp1JWoA%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/dataprep/engine_spans_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/dataprep/engine_spans_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl?sv=2019-02-02&sr=b&sig=NABacDdqeMvZ%2BwhkIY70Qow7U9LTeunTnJ14UF8yg6c%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/dataprep/python_span_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/dataprep/python_span_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl?sv=2019-02-02&sr=b&sig=3cRzocEnOdq1BBf5vgmvanisiHGGiYdJFuyfyM9UbJ4%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=AUAaM%2B1cbAguSVu0k3b824XouOuusSW6%2BUvQRJ32M%2BM%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone_project_1609112943_031f3fe8/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=jqJKE4XJPHDt%2FgryuSkK1FDi1J%2FCIWeJi4JFh0vCYtg%3D&st=2020-12-27T23%3A49%3A49Z&se=2020-12-28T07%3A59%3A49Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_572a03ea2f39854fce6334cb40732f66ee9972bc5f0ddcda4eb0907d7bd37004_d.txt\"], [\"logs/azureml/dataprep/engine_spans_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl\", \"logs/azureml/dataprep/python_span_l_77eb71db-0ec8-4db1-9abd-c0e97b6ab12c.jsonl\"], [\"logs/azureml/103_azureml.log\"]], \"run_duration\": \"0:10:44\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Strength:\", \"run_id\": \"capstone_project_1609112943_031f3fe8\", \"categories\": [0], \"series\": [{\"data\": [0.5]}]}, {\"name\": \"Max iterations:\", \"run_id\": \"capstone_project_1609112943_031f3fe8\", \"categories\": [0], \"series\": [{\"data\": [10]}]}, {\"name\": \"Accuracy\", \"run_id\": \"capstone_project_1609112943_031f3fe8\", \"categories\": [0], \"series\": [{\"data\": [0.6753246753246753]}]}], \"run_logs\": \"2020-12-27 23:59:09,417|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-12-27 23:59:09,418|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-12-27 23:59:09,426|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-12-27 23:59:09,427|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-12-27 23:59:09,776|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fe922c1b378> for run source azureml.scriptrun\\n2020-12-27 23:59:09,816|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-27 23:59:09,825|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-12-27 23:59:09,825|azureml.core.authentication|DEBUG|Time to expire 1813795.17437 seconds\\n2020-12-27 23:59:09,825|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2020-12-27 23:59:09,826|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2020-12-27 23:59:09,872|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,872|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,872|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,873|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,873|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,873|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,873|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:09,917|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-27 23:59:09,917|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-27 23:59:09,991|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:09,992|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'c318df8a-85be-41ed-a2e4-cecb29eb5aa8', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-12-27 23:59:09,992|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-27 23:59:09,993|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-12-27 23:59:09,993|azureml.WorkerPool|DEBUG|[START]\\n2020-12-27 23:59:09,993|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-12-27 23:59:09,993|azureml.RunStatusContext|DEBUG|[START]\\n2020-12-27 23:59:09,993|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-12-27 23:59:10,003|azureml.MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:10,003|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:10,003|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-12-27 23:59:10,003|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-12-27 23:59:10,003|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8\\n2020-12-27 23:59:10,003|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-27 23:59:10,003|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8\\n2020-12-27 23:59:26,193|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-12-27 23:59:26,193|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,194|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,194|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,194|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,194|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,195|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,195|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-27 23:59:26,229|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,230|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-27 23:59:26,300|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:26,301|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'c318df8a-85be-41ed-a2e4-cecb29eb5aa8', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-12-27 23:59:26,301|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-27 23:59:26,302|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-27 23:59:26,302|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-27 23:59:26,303|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-27 23:59:26,518|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-27 23:59:26,518|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8\\n2020-12-27 23:59:26,519|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8 to /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8\\n2020-12-27 23:59:26,519|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-132094/azureml/capstone_project_1609112943_031f3fe8/mounts/workspaceblobstore/azureml/capstone_project_1609112943_031f3fe8\\n2020-12-27 23:59:26,519|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-12-27 23:59:26,519|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-12-27 23:59:26,519|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,519|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-27 23:59:26,519|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-27 23:59:26,519|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-27 23:59:26,519|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,520|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,521|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,521|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-27 23:59:26,599|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:26,601|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,601|azureml.MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,601|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,601|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,601|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-27 23:59:26,602|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,603|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,603|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,603|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-27 23:59:26,662|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:26,662|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-12-27 23:59:26,662|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,663|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-27 23:59:26,664|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-27 23:59:26,664|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,664|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,664|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,664|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-27 23:59:26,717|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:26,717|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,717|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-27 23:59:26,718|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-27 23:59:26,719|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,720|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-12-27 23:59:26,720|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-12-27 23:59:26,720|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2020-12-27 23:59:26,720|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-12-27 23:59:26,720|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-12-27 23:59:26,721|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-12-27 23:59:26,721|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2020-12-27 23:59:26,721|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-12-27 23:59:26,721|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-12-27 23:59:26,722|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,722|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-12-27 23:59:26,722|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-12-27 23:59:26,723|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2020-12-27 23:59:26,723|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-12-27 23:59:26,728|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-12-27 23:59:26,728|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-12-27 23:59:26,729|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-12-27 23:59:26,729|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-12-27 23:59:26,729|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-12-27 23:59:26,729|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-12-27 23:59:26,729|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-27 23:59:26,729|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-27 23:59:26,729|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2020-12-27 23:59:26,883|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 9.894371032714844e-05 seconds.\\n\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,980|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-27 23:59:26,981|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-27 23:59:26,981|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-27 23:59:27,042|azureml._SubmittedRun#capstone_project_1609112943_031f3fe8.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-27 23:59:32,048|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2020-12-27 23:59:32,105|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-12-27 23:59:32,105|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-12-27 23:59:32,106|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-12-27 23:59:32,106|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperdrive Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling( {\n",
    "        \"--C\": uniform(0.50,1.00),\n",
    "       \"--max_iter\" : choice(10,20,30)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "\n",
    "\n",
    "#sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='./conda_dependencies.yml')\n",
    "#envit = Environment.get(workspace=ws,name='myenv')\n",
    "\n",
    "#config  = ScriptRunConfig(source_directory='.',\n",
    "                         #script='train.py',                         \n",
    "                         #compute_target=cpu_cluster,\n",
    "                         #environment=env)\n",
    "\n",
    "\n",
    "\n",
    "#hyperdrive_run_config = <your config here>\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "                                   hyperparameter_sampling = ps,\n",
    "                                   primary_metric_name = 'Accuracy',\n",
    "                                   max_total_runs = 20,\n",
    "                                   max_concurrent_runs = 4,\n",
    "                                   primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                   policy = policy,\n",
    "                                   run_config = src)\n",
    "\n",
    "#estimator=estimator use to replace estimator in hyperdriveconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3948a4e4cb4b6d933fad290aa59846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/capstone_project/runs/HD_6d059a1d-10a1-434d-8a06-c3e670fff848?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-132094/workspaces/quick-starts-ws-132094\", \"run_id\": \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848\", \"run_properties\": {\"run_id\": \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848\", \"created_utc\": \"2020-12-28T00:02:42.436672Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"5d2c64b7-bc73-411e-b379-6c981760d982\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"uniform\\\", [0.5, 1.0]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"uniform\\\", [0.5, 1.0]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourceGroups/aml-quickstarts-132094/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-132094/experiments/capstone_project\\\", \\\"SubscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-132094\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-132094\\\", \\\"ExperimentName\\\": \\\"capstone_project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [\\\"--C\\\", 0.5, \\\"--max_iter\\\", 10], \\\"target\\\": \\\"puru-compute-new\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": \\\"tutorial-env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-dataset-runtime[pandas,fuse]~=1.19.0\\\", \\\"azureml-defaults~=1.19.0\\\"]}, \\\"scikit-learn==0.22.1\\\"], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"5d2c64b7-bc73-411e-b379-6c981760d982\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"fc3f242a-65a9-4ba1-b145-1c4717abc69b\\\", \\\"amlClientSessionId\\\": \\\"c4800f73-533a-4efc-8750-124932c89c7d\\\", \\\"subscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourceGroups/aml-quickstarts-132094/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-132094/experiments/capstone_project\\\", \\\"SubscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-132094\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-132094\\\", \\\"ExperimentName\\\": \\\"capstone_project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [\\\"--C\\\", 0.5, \\\"--max_iter\\\", 10], \\\"target\\\": \\\"puru-compute-new\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": \\\"tutorial-env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-dataset-runtime[pandas,fuse]~=1.19.0\\\", \\\"azureml-defaults~=1.19.0\\\"]}, \\\"scikit-learn==0.22.1\\\"], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"5d2c64b7-bc73-411e-b379-6c981760d982\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"fc3f242a-65a9-4ba1-b145-1c4717abc69b\\\", \\\"amlClientSessionId\\\": \\\"c4800f73-533a-4efc-8750-124932c89c7d\\\", \\\"subscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-12-28T00:02:43.052223\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-12-28T00:02:43.052223\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"4295dd1c1a2c24254653aff229ee62fc16f361242060eca566b486285b4f9553\\\"\", \"progress_metadata_digest\": \"\\\"4295dd1c1a2c24254653aff229ee62fc16f361242060eca566b486285b4f9553\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-12-28T00:02:43.052223\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-12-28T00:02:43.052223\\\"\", \"_aml_system_environment_preparation_status\": \"PREPARING\", \"environment_preparation_status\": \"PREPARING\", \"_aml_system_prepare_run_id\": \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_preparation\", \"prepare_run_id\": \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_preparation\", \"_aml_system_HD_6d059a1d-10a1-434d-8a06-c3e670fff848_0\": \"{\\\"--C\\\": 0.8110157631536387, \\\"--max_iter\\\": 30}\", \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_0\": \"{\\\"--C\\\": 0.8110157631536387, \\\"--max_iter\\\": 30}\", \"_aml_system_HD_6d059a1d-10a1-434d-8a06-c3e670fff848_1\": \"{\\\"--C\\\": 0.7578728914800195, \\\"--max_iter\\\": 30}\", \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_1\": \"{\\\"--C\\\": 0.7578728914800195, \\\"--max_iter\\\": 30}\", \"_aml_system_HD_6d059a1d-10a1-434d-8a06-c3e670fff848_2\": \"{\\\"--C\\\": 0.9230997914026359, \\\"--max_iter\\\": 10}\", \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_2\": \"{\\\"--C\\\": 0.9230997914026359, \\\"--max_iter\\\": 10}\", \"_aml_system_HD_6d059a1d-10a1-434d-8a06-c3e670fff848_3\": \"{\\\"--C\\\": 0.9929658165834947, \\\"--max_iter\\\": 30}\", \"HD_6d059a1d-10a1-434d-8a06-c3e670fff848_3\": \"{\\\"--C\\\": 0.9929658165834947, \\\"--max_iter\\\": 30}\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg132094.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_6d059a1d-10a1-434d-8a06-c3e670fff848/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=XXE%2F6XBhy7uag4G%2FFU8i6fd0DKN4oZ2nnmQqciAaAPM%3D&st=2020-12-27T23%3A52%3A46Z&se=2020-12-28T08%3A02%3A46Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:00:04\", \"hyper_parameters\": {\"--C\": [\"uniform\", [0.5, 1.0]], \"--max_iter\": [\"choice\", [[10, 20, 30]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2020-12-28T00:02:42.734670][API][INFO]Experiment created\\r\\n[2020-12-28T00:02:43.262368][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2020-12-28T00:02:43.3918010Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-12-28T00:02:43.557025][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_6d059a1d-10a1-434d-8a06-c3e670fff848\n",
      "Web View: https://ml.azure.com/experiments/capstone_project/runs/HD_6d059a1d-10a1-434d-8a06-c3e670fff848?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-132094/workspaces/quick-starts-ws-132094\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2020-12-28T00:02:42.734670][API][INFO]Experiment created<END>\\n\"\"<START>[2020-12-28T00:02:43.262368][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2020-12-28T00:02:43.3918010Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2020-12-28T00:02:43.557025][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n"
     ]
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "hyperdrive_run = exp.submit(hyperdrive_config)\n",
    "RunDetails(hyperdrive_run).show()\n",
    "# wait for completion\n",
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# register model for future deployment\n",
    "# os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "description = 'Diabetec'\n",
    "tags = {'area': 'health', 'type': 'classification'}\n",
    "\n",
    "hyperdrive_model = best_run.register_model(model_name='purumodel',\n",
    "                                                      model_path='outputs/purumodel.pkl',\n",
    "                                                      tags=tags,\n",
    "                                                      description=description)\n",
    "\n",
    "print(hyperdrive_model.name, hyperdrive_model.id, hyperdrive_model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'purumodel.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"health\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict diabetec with sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'purumodel')\n",
    "\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"tutorial-env\", version=\"1\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service_name = 'puru-svc-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=service_name, \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws,name='purumodel')\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4, enable_app_insights=True, auth_enabled=True)\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=envit)\n",
    "\n",
    "service = Model.deploy(ws, \"puruservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "payload = json.dumps({\n",
    "    'data': x_data[0:2].tolist(),\n",
    "    'method': 'predict_proba'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print logs\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "# Requires the config to be downloaded first to the current working directory\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Set with the deployment name\n",
    "name = \"puruservice\"\n",
    "\n",
    "# load existing web service\n",
    "service = Webservice(name=name, workspace=ws)\n",
    "logs = service.get_logs()\n",
    "\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
